{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as seabornInstance \n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "hypothesis = x_train * W + b \n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(5001):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name = \"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name = \"bias\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict={X: [1,2,3,4,5], Y:[2.1, 3.1,4.1,5.1,6.1] } )\n",
    "#     if step % 20 == 0:\n",
    "#         print(step, cost_val, W_val, b_val)\n",
    "        \n",
    "        \n",
    "print(sess.run(hypothesis, feed_dict = {X:[1.5, 3.5] } ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "hypothesis = X * W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = X * W\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "# Minimizer: Gradient Descent\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rat e = 0.1)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21) :\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict = {X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "#Set wrong model weights\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "hypothesis = X*W\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimizer: Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73.,93.,89.,96.,73.]\n",
    "x2_data = [80.,88.,91.,98.,66.]\n",
    "x3_data = [75.,93.,90.,100.,70.]\n",
    "y_data = [152.,185.,180.,196.,142.]\n",
    "\n",
    "#placeholders for a tensor that will be always fed\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x1 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001) : \n",
    "    cost_val, hy_val, _= sess.run([cost, hypothesis, train], feed_dict= {x1: x1_data, x2: x2_data, x3:x3_data, Y: y_data})\n",
    "#     if step %10 ==0:\n",
    "#         print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73.,80.,75.], [93.,88.,93.],[89.,91.,90.],[96.,98.,100.],[73.,66.,70.]]\n",
    "y_data = [[152.], [185.],[180.],[196.],[142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001) : \n",
    "    cost_val, hy_val, _= sess.run([cost, hypothesis, train], feed_dict= {X: x_data,Y: y_data})\n",
    "    if step %10 ==0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv', delimiter = ',')\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "\n",
    "# import csv\n",
    "\n",
    "# x_data = []\n",
    "# y_data = []\n",
    "# with open('data-01-test-score.csv') as csv_file:\n",
    "#     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "#     line_count = 0\n",
    "\n",
    "#     for row in csv_reader:\n",
    "#         x_data.append(row[1:])\n",
    "#         y_data.append(row[0])\n",
    "#         line_count += 1\n",
    "#     print(f'Processed {line_count} lines.')\n",
    "\n",
    "\n",
    "# make sure the shape and data are OK\n",
    "# print(x_data)\n",
    "# print(y_data)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001) : \n",
    "    cost_val, hy_val, _= sess.run([cost, hypothesis, train], feed_dict= {X: x_data,Y: y_data})\n",
    "#     if step %10 ==0:\n",
    "#         print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)\n",
    "        \n",
    "# Ask my score\n",
    "# print(sess.run(W[1]))\n",
    "# print(sess.run(b))\n",
    "# print(\"your score will be\", sess.run(hypothesis, feed_dict = {X: [[100,70,101]]}))\n",
    "# print(\"other scores will be \", sess.run(hypothesis, feed_dict={X: [[60,70,110], [90,100,80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('CASP.csv', delimiter = ',')\n",
    "x_data = xy[:, 0:-1]\n",
    "train_x_data = preprocessing.scale(x_data)\n",
    "train_y_data = xy[:, [-1]]\n",
    "\n",
    "\n",
    "testxy = np.loadtxt('Test_CASP.csv', delimiter = ',')\n",
    "test_x_data = preprocessing.scale(testxy[:, 0:-1])\n",
    "test_y_data = testxy[:, [-1]]\n",
    "\n",
    "\n",
    "#make sure the shape and data are OK\n",
    "# print(train_x_data)\n",
    "# print(y_data)\n",
    "# print(test_x_data)\n",
    "# print(test_y_data)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 9])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([9,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(5001) : \n",
    "    cost_val, hy_val, _= sess.run([cost, hypothesis, train], feed_dict= {X: train_x_data,Y: train_y_data})\n",
    "#     if step %1000 ==0:\n",
    "#         print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)\n",
    "\n",
    "y_predicted = sess.run(hypothesis, feed_dict = {X:test_x_data})\n",
    "y_predict = sess.run(hypothesis, feed_dict = {X:train_x_data})\n",
    "\n",
    "print('1Mean Absolute Error:', metrics.mean_absolute_error(train_y_data, y_predict))\n",
    "print('1Mean Squared Error:', metrics.mean_squared_error(train_y_data, y_predict))\n",
    "print('1Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(train_y_data, y_predict)))\n",
    "print()\n",
    "print('2Mean Absolute Error:', metrics.mean_absolute_error(test_y_data, y_predicted))\n",
    "print('2Mean Squared Error:', metrics.mean_squared_error(test_y_data, y_predicted))\n",
    "print('2Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_data, y_predicted)))\n",
    "\n",
    "\n",
    "# #predict\n",
    "# print(\"Prediction :\", sess.run(prediction, feed_dict= {X: test_x_data}))\n",
    "# #calculate accuracy\n",
    "# print(\"Accuracy :\", sess.run(accuracy, feed_dict= {X: test_x_data, Y: test_y_data}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "dataset = pd.read_csv('/home/jinho/Downloads/CASP.csv')\n",
    "\n",
    "dataset.describe()\n",
    "\n",
    "X = dataset[['RMSD', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']].values\n",
    "y = dataset['F9'].values\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.tight_layout()\n",
    "# seabornInstance.distplot(dataset['F9'])\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 0)\n",
    "# print(y_train)\n",
    "\n",
    "# regressor = LinearRegression()  \n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "# df1 = df.head(25)\n",
    "# print(df1)\n",
    "# df1.plot(kind='bar',figsize=(10,8))\n",
    "# plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "# plt.show()\n",
    "\n",
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "# print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('airfoil_self_noise.dat', delimiter = '\\t',dtype = np.float32)\n",
    "\n",
    "x_data = xy[:1202, 0:-1]\n",
    "train_x_data = preprocessing.normalize(x_data, norm='l1')\n",
    "train_y_data = xy[:1202, [-1]]\n",
    "\n",
    "tx_data = xy[1202:, 0:-1]\n",
    "test_x_data = preprocessing.normalize(tx_data, norm='l1')\n",
    "test_y_data = xy[1202:, [-1]]\n",
    "\n",
    "#make sure the shape and data are OK\n",
    "# print(train_x_data)\n",
    "# print(train_y_data)\n",
    "# print(test_x_data)\n",
    "# print(test_y_data)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.tight_layout()\n",
    "# seabornInstance.distplot(train_y_data)\n",
    "\n",
    "# plt.scatter(train_x_data[:, 4:5], train_y_data,  color='black')\n",
    "# plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.show()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, 5])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([5,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) + (0.00001 * tf.reduce_sum(tf.square(W)))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10001) : \n",
    "    cost_val, hy_val, _= sess.run([cost, hypothesis, train], feed_dict= {X: train_x_data,Y: train_y_data})\n",
    "#     if step %1000 ==0:\n",
    "#         print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)\n",
    "        \n",
    "y_predicted = sess.run(hypothesis, feed_dict = {X:test_x_data})\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_data, y_predicted))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_y_data, y_predicted))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_data, y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "xy = np.loadtxt('airfoil_self_noise.dat', delimiter = '\\t',dtype = np.float32)\n",
    "\n",
    "x_data = xy[:1202, 0:-1]\n",
    "train_y_data = xy[:1202, [-1]]\n",
    "train_x_data = preprocessing.normalize(x_data, norm='l2')\n",
    "# train_x_data = MinMaxScaler(train_x_data)\n",
    "# train_x_data = preprocessing.scale(x_data)\n",
    "\n",
    "tx_data = xy[1202:, 0:-1]\n",
    "test_y_data = xy[1202:, [-1]]\n",
    "test_x_data = preprocessing.normalize(tx_data, norm='l2')\n",
    "\n",
    "regressor = LinearRegression()  \n",
    "regressor.fit(train_x_data, train_y_data)\n",
    "\n",
    "y_pred = regressor.predict(test_x_data)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_data, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_y_data, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_data, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "xy = np.loadtxt('airfoil_self_noise.dat', delimiter = '\\t',dtype = np.float32)\n",
    "\n",
    "x_data = xy[:1202, 0:-1]\n",
    "train_y_data = xy[:1202, [-1]]\n",
    "train_x_data = preprocessing.normalize(x_data, norm='l1')\n",
    "# train_x_data = MinMaxScaler(train_x_data)\n",
    "# train_x_data = preprocessing.scale(x_data)\n",
    "\n",
    "tx_data = xy[1202:, 0:-1]\n",
    "test_y_data = xy[1202:, [-1]]\n",
    "test_x_data = preprocessing.normalize(tx_data, norm='l1')\n",
    "\n",
    "ridgeReg = Ridge(alpha = 1e-5)\n",
    "ridgeReg.fit(train_x_data,train_y_data)\n",
    "\n",
    "y_pred =ridgeReg.predict(test_x_data)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_data, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_y_data, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_data, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "xy = np.loadtxt('airfoil_self_noise.dat', delimiter = '\\t',dtype = np.float32)\n",
    "\n",
    "x_data = xy[:1202, 0:-1]\n",
    "train_y_data = xy[:1202, [-1]]\n",
    "train_x_data = preprocessing.normalize(x_data, norm='l2')\n",
    "# train_x_data = MinMaxScaler(train_x_data)\n",
    "# train_x_data = preprocessing.scale(x_data)\n",
    "\n",
    "tx_data = xy[1202:, 0:-1]\n",
    "test_y_data = xy[1202:, [-1]]\n",
    "test_x_data = preprocessing.normalize(tx_data, norm='l2')\n",
    "\n",
    "lassoReg = Lasso(alpha=1e-5)\n",
    "lassoReg.fit(train_x_data ,train_y_data)\n",
    "\n",
    "y_pred =lassoReg.predict(test_x_data)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_y_data, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_y_data, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_y_data, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
